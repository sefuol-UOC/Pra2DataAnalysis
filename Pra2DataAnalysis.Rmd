---
title: 'PRA2 - Tipología y ciclo de vida de los datos: Limpieza y análisis de datos'
author: "Sergio Funes, David Ortiz"
date: "Junio de 2021"
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
    highlight: default
    number_sections: no
    theme: cosmo
    includes:
      in_header: PRA_header.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

```{r, include=FALSE}
library(VIM)
```

# 1. Descripción del dataset y problema de interés

El conjunto de datos es el 'Dataset recruitment data', disponible en el repositorio [en Kaggle](https://www.kaggle.com/rafunlearnhub/recruitment-data). Está formado por 11 características para un total de 614 personas, en un conjunto de datos que refleja el estado de contratación. Este conjunto de datos es interesante puesto que permite identificar las relaciones más directas con un proceso de contratación satisfactorio, lo que puede permitir actuar para mejorar las posibilidades de contratación, o simplemente para detectar relaciones entre distintos usuarios tipo y variables tan relevantes como el salario.

Las características de las que dispone el conjunto de datos son las siguientes:

* **Número de serie**. Número del registro.

* **Género**. Si el sujeto es hombre o mujer.

* **Experiencia con Python**. Si el sujeto tiene experiencia de programación en Python.

* **Años de experiencia**. Número de años de experiencia del sujeto.

* **Educación**. Si el sujeto es graduado universitario o no.

* **Prácticas**. Si el sujeto ha hecho unas prácticas o no.

* **Puntuación**. Puntuación del sujeto.

* **Salario** (*10e4). Salario del sujeto, en decenas de miles de rupias.

* **Histórico de ofertas**. Si el sujeto ha tenido ofertas laborales.

* **Localización**. Tipo de localización del sujeto en relación con la ciudad: urbana, semiurbana o rural.

* **Estado de contratación**. Si el sujeto fue contratado o no.

A partir de este conjunto de datos, se pretende determinar que variables influyen más a la hora de decidir si un candidato es contratado o no. Además, se podrán crear modelos predictivos para predecir la decisión final.

Este análisis adquiere importancia a la hora de reclutar nuevos empleados en una empresa principalmente de informática, ya que a partir de su experiencia de programación, su educación y su experiencia, tendremos una primera aproximación sobre si un empleado será contratado o no.

Asímismo, durante la realización de esta práctica nos proponemos dar respuesta a tres preguntas principales:

1. Si hay correlación entre la experiencia del usuario y la puntuación otorgada a cada uno de ellos y el salario que consigue.

2. Si las mujeres cobran distinto a los hombres y si, en caso de hacerlo, su salario es inferior al de estos.

3. Si hay factores de protección o riesgo importantes que afecten a la contratación y en qué grado.

# 2. Integración y selección de los datos de interés

Realizamos una lectura de los datos:

```{r}
data <- read.csv("recruitment_decision_tree.csv", header = TRUE, stringsAsFactors = TRUE, na.strings = "")
head(data)
```

```{r}
sapply(data, function(x) class(x))
```

Observamos que los tipos de datos asignados son los correctos. A continuación, podemos prescindir de la variable Serial_no, ya que no nos aporta información sobre el candidato, únicamente representa que número de candidato es.

```{r}
data <- data[, -(1)]
```


# 3. Limpieza de los datos

## 3.1. Ceros y elementos vacíos

Comprobamos si nuestro conjunto de datos contiene elementos vacíos:

```{r}
sapply(data, function(x) sum(is.na(x)))
```

Podemos observar que hay 134 elementos vacíos entre las variables Gender, Python_exp, Experience_Years, Internship, Salary...10E4 y Offer_History. Procederemos a emplear un método de imputación de valores basada en k vecinos más próximos. Utilizaremos la función kNN de la libreria VIM:

```{r}
suppressWarnings(suppressMessages(library(VIM)))

data$Gender <- kNN(data)$Gender
data$Python_exp <- kNN(data)$Python_exp
data$Experience_Years <- kNN(data)$Experience_Years
data$Internship <- kNN(data)$Internship
data$Salary...10E4 <- kNN(data)$Salary...10E4
data$Offer_History <- kNN(data)$Offer_History

sapply(data, function(x) sum(is.na(x)))
```

Después de la imputación de valores, podemos comprobar que ya no existen valores vacíos en nuestro conjunto de datos.

## 3.2. Valores extremos

Identificaremos los valores outliers de dos formas diferentes, utilizando un diagrama de caja y utilizando la función boxplots.stats() de R. Representaremos los datos de las variables numéricas Score y Salary...10E4. Primeramente representaremos la variable Score:

```{r}
boxplot(data$Score)
boxplot.stats(data$Score)$out
```

Podemos observar que la variable Score contiene muchos outliers. En este caso, podemos deshacernos de los valores más lejanos, ya que aunque haya valores fuera del rango, no podemos asumir que sean outliers y no personas altamente cualificadas para ser contratadas. Para deshacernos de los outliers, le daremos valor vacío a partir de cierto rango y después utilizaremos la función kNN nuevamente para la imputación de los valores:

```{r}
data$Score[data$Score > 23000] <- NA

data$Score <- kNN(data)$Score

boxplot(data$Score)
```

Puede observarse que han desaparecido los outliers más lejanos. Continuaremos con la variable Salary...10E4:

```{r}
boxplot(data$Salary...10E4)
boxplot.stats(data$Salary...10E4)$out
```

```{r}
data$Salary...10E4[data$Salary...10E4 > 500] <- NA

data$Salary...10E4 <- kNN(data)$Salary...10E4

boxplot(data$Salary...10E4)
```

En la variable Salary...10E4, hemos realizado el mismo proceso que en la variable anterior.

## 3.3. Exportación de los datos preprocesados

Después de leer y validar el conjunto de datos, limpieza de los elementos vacíos y extremos, procedemos a guardar los datos en un fichero denominado "recruitment_decision_tree_clean.csv":

```{r}
write.csv(data, "recruitment_decision_tree_clean.csv")
```


# 4. Análisis de los datos

## 4.1. Selección de datos

Pasamos a la selección de las variables de interés para su análisis estadístico posterior. Encontramos aquí las variables categóricas más relevantes.

```{r}
# Per gender
data.women <- data[data$Gender == "Female", ]
data.men <- data[data$Gender == "Male", ]

# Per location type
data.urban <- data[data$Location == "Urban", ]
data.semiurban <- data[data$Location == "Semiurban", ]
data.rural <- data[data$Location == "Rural", ]

# Per education level
data.graduated <- data[data$Education == "Graduate", ]
data.not_graduated <- data[data$Education == "Not Graduate", ]

# Target var: recruitment status
data.recruited <- data[data$Recruitment_Status == "Y", ]
data.not_recruited <- data[data$Recruitment_Status == "N", ]
```

## 4.2. Comprobación de normalidad y homogeneidad de la varianza

Se comprueba ahora la normalidad de las variables cuantitativas, mediante el test de normalidad de Anderson-Darling. Si el p-valor de es superior al nivel de significancia de $\alpha = 0,05$, entonces podemos concluir que la variable en cuestión es normal.

```{r}
library(nortest)

num_vars <- c("Experience_Years", "Score", "Salary...10E4")
alpha <- 0.05

for (col in num_vars){
  p_value = ad.test(data[, col])$p.value
  if (p_value > alpha){
    print(paste0(col, ": Normal (p = ", p_value, ")"))
  } else {
    print(paste0(col, ": Not normal (p = ", p_value, ")"))
  }
}
```

Por tanto vemos que las tres variables numéricas siguen una distribución no normal.

Para estudiar la homogeneidad de las varianzas aplicamos el test de Fligner-Killeen. Se pretende comprobar esta en la relación del género de los candidatos con el salario asociado a estos. Para este test, la hipótesis nula, $H_0$, sostiene la igualdad de varianzas para ambos grupos. Por su parte, $H_1$ supondría varianzas diferentes.

Si el p-valor es superior a un nivel de significancia del 0,05, se aceptará dicha hipótesis nula y por tanto la igualdad de varianzas. Aplicamos el test sobre los salarios, una de las variables de interés a estudiar.

```{r}
# Salary
fligner.test(Salary...10E4 ~ Gender, data=data)
```

Puesto que el p-valor es mayor a 0,05, se acepta la hipótesis nula y por tanto se asume la igualdad de varianzas para ambas muestras.


## 4.3. Pruebas estadísticas

Realizamos ahora varios análisis estadísticos que nos permitan responder las preguntas de interés planteadas sobre el conjunto de datos.

### 4.3.1. Correlación de la experiencia y puntuación de los candidatos con el salario

Comprobamos la correlación de la experiencia y puntuación de los candidatos con el salario, con el fin de comprobar en qué medida están asociadas estas métricas con una mayor retribución económica.

```{r}
# Experience vs salary
corr_exp_salary = cor(data$Experience_Years, data$Salary...10E4)
print(paste("Correlation of experience and salary:", round(corr_exp_salary, 3)))
# Score vs salary
corr_score_salary = cor(data$Score, data$Salary...10E4)
print(paste("Correlation of score and salary:", round(corr_score_salary, 3)))
```

Vemos que la correlación entre la experiencia y el salario es más bien débil para las muestras recogidas en el conjunto de datos, con un valor de `r round(corr_exp_salary, 3)`. No obstante, la puntuación tiene una correlación superior, aunque todavía moderada, de `r round(corr_score_salary, 3)`.

### 4.3.2. Contraste de hipótesis: salario de mujeres y hombres

Se pretende comprobar además si el salario de las mujeres y el de los hombres es diferente. Para ello, realizamos un contraste de hipótesis bilateral definiendo:

* $H_0: \mu_{mujeres} = \mu_{hombres}$

* $H_1: \mu_{mujeres} \ne \mu_{hombres}$

Donde la hipótesis nula, $H_0$, corresponde a la igualdad de salarios, y la hipótesis alternativa $H_1$, corresponde a la desigualdad de estos. Si bien la distribución no es normal, contamos con un buen tamaño muestral muy superior a 30, por lo que el teorema del límite central nos permite realizar test estadístico sobre la media asumiendo la normalidad de esta.

```{r}
t.test(data.women$Salary...10E4, data.men$Salary...10E4,
       alternative="two.sided", conf.level=0.95)
```

Al obtener un `p-valor` inferior a 0.05, el valor de significancia para un nivel de confianza del 95%, rechazamos la hipótesis nula. Por tanto, podemos afirmar que los salarios de mujeres y hombres son diferentes.

Para concretar más, podemos aplicar una hipótesis unilateral que verifique si efectivamente y como se puede sospechar, los sueldos de las mujeres son inferiores a los de los hombres. Para ello, definimos ahora las hipótesis:

* $H_0: \mu_{mujeres} = \mu_{hombres}$

* $H_1: \mu_{mujeres} < \mu_{hombres}$

En este caso la hipótesis alternativa, $H_1$, corresponde al supuesto en el que las mujeres tienen un salario medio inferior al de los hombres. Realizamos el test estadístico.

```{r}
t.test(data.women$Salary...10E4, data.men$Salary...10E4,
       alternative="less", conf.level=0.95)
```

En este caso vemos, de nuevo, como el `p-valor` es inferior al nivel de significancia adoptado, por lo que se rechaza la hipótesis nula y se concluye que, la media de los salarios de las mujeres es inferior al de los hombres con una confianza del 95%.

### 4.3.3. Regresión logística

Puesto que buena parte de las variables con las que contamos son de tipo categórico, podemos comprobar la relación entre estas y si finalmente el candidato fue contratado o no.

Podemos comprobar si existe relación entre algunas variables y la variable objetivo mediante el test $\chi^2$ de Pearson.

```{r}
# Get relation for all variables
data.colnames <- colnames(data[, -(10)])
alpha <- 0.05
print("Checking against Recruitment_Status:")
for (col in data.colnames){
  p_value <- chisq.test(table(data$Recruitment_Status, data[, col]),
                        simulate.p.value=TRUE)$p.value
  p_value <- round(p_value, 4)
  if (p_value > 0.05){
    print(paste0(col, ": not related (p = ", p_value, ")"))
  } else {
    print(paste0(col, ": related (p = ", p_value, ")"))
  }
}
```

Vemos que las variables que mantienen relación con la contratación son, según dicho test la educación, el historial de ofertas y la localización. Asimismo, vemos que la experiencia con Python es marginalmente relevante, por lo que la añadimos por la información que pueda aportar al modelo. Reajustamos las referencias de estas variables, con el estado más bajo (no graduado, sin ofertas previas, localización rural y sin experiencia en Python) como tal.

```{r}
# Relevel related variables
data$Education_R <- relevel(data$Education, ref="Not Graduate")
data$Offer_History_R <- relevel(as.factor(data$Offer_History), ref="0")
data$Location_R <- relevel(data$Location, ref="Rural")
data$Python_exp_R <- relevel(data$Python_exp, ref="No")

# Logistic regression
logistic_formula <- Recruitment_Status ~ Education_R + Offer_History_R + Location_R + Python_exp_R
logistic_model <- glm(formula=logistic_formula, data=data,
                      family=binomial(link = 'logit'))

summary(logistic_model)
```

Sobre las variables estudiadas, se observa una gran significancia para el historial de ofertas laborales registrado, así como la localización, en el caso de que esta esté calificada como semiurbana. Por último, vemos una significancia menor, aunque no despreciable, de la experiencia de programación en Python. Podemos calcular las *Odds-Ratio* (OR), para comprobar cuál es el efecto de estas tres variables:

```{r}
## Odds-Ratio
exp(coefficients(logistic_model))
```

Vemos por tanto que respecto a la referencia multivariable tomada, vemos que corresponde al historial de ofertas laborales una probabilidad hasta 55 veces superior, por lo que supone un claro factor de riesgo en términos estadísticos. Por su parte, tener una localización semiurbana sería hasta 2,5 veces (+150%) más probable, de nuevo un factor de riesgo, para la contratación. Por su parte y sorprendentemente, contar con experiencia en Python reduce la probabilidad de contratación, para el conjunto de datos estudiado, en hasta un 43% respecto a los candidatos que no cuentan con ella, por lo que sería un factor de protección respecto a la contratación.

Es interesante tener en cuenta que, tal y como se indicó en la descripción del problema, una vez construido este modelo, puede ser utilizado para predecir la contratación, o no, de candidatos a ofertas de empleo, basándonos en las variables utilizadas para su construcción: la educación, el tipo de localización, el historial de ofertas y la experiencia de programación en Python.


# 5. Representación de resultados


# 6. Resolución y conclusiones


# 7. Código


```{r table-simple, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
require(pander)
panderOptions('table.split.table', Inf)
my.data <- "   Contribuciones | Firma
  Investigación previa        | DO, SF         
  Redacción de las respuestas | DO, SF
  Desarrollo código           | DO, SF"
df <- read.delim(textConnection(my.data),header=FALSE,sep="|",strip.white=TRUE,stringsAsFactors=FALSE)
names(df) <- unname(as.list(df[1,])) # put headers on
df <- df[-1,] # remove first row
row.names(df)<-NULL
pander(df, style = 'rmarkdown')
```