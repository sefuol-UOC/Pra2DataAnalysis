---
title: 'PRA2 - Tipología y ciclo de vida de los datos: Limpieza y análisis de datos'
author: "Sergio Funes, David Ortiz"
date: "Junio de 2021"
output:
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
    highlight: default
    number_sections: no
    theme: cosmo
    includes:
      in_header: PRA_header.html
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

```{r, include=FALSE}
library(VIM)
```

# 1. Descripción del dataset

El conjunto de datos es Dataset recruitment data [en Kaggle](https://www.kaggle.com/rafunlearnhub/recruitment-data). Está formado por 11 características que presentan 614 personas. Las características son las siguientes:

* **Número de serie**. Número del registro.

* **Género**. Si el sujeto es hombre o mujer.

* **Experiencia con Python**. Si el sujeto tiene experiencia de programación en Python.

* **Años de experiencia**. Número de años de experiencia del sujeto.

* **Educación**. Si el sujeto es graduado universitario o no.

* **Prácticas**. Si el sujeto ha hecho unas prácticas o no.

* **Puntuación**. Puntuación del sujeto.

* **Salario** (*10e4). Salario del sujeto, en decenas de miles de rupias.

* **Histórico de ofertas**. Si el sujeto ha tenido ofertas laborales.

* **Localización**. Tipo de localización del sujeto en relación con la ciudad: urbana, semiurbana o rural.

* **Estado de contratación**. Si el sujeto fue contratado o no.

A partir de este conjunto de datos, se pretende determinar que variables influyen más a la hora de decidir si un candidato es contratado o no. Además, se podrán crear modelos predictivos para predecir la decisión final.

Este análisis adquiere importancia a la hora de reclutar nuevos empleados en una empresa principalmente de informática, ya que a partir de su experiencia de programación, su educación y su experiencia, tendremos una primera aproximación sobre si un empleado será contratado o no.


# 2. Integración y selección de los datos de interés

Realizamos una lectura de los datos:

```{r}
data <- read.csv("recruitment_decision_tree.csv", header = TRUE, stringsAsFactors = TRUE)
head(data)
```

```{r}
sapply(data, function(x) class(x))
```

Observamos que los tipos de datos asignados son los correctos. A continuación, podemos prescindir de la variable Serial_no, ya que no nos aporta información sobre el candidato, únicamente representa que número de candidato es.

```{r}
data <- data[, -(1)]
```


# 3. Limpieza de los datos

## 3.1. Ceros y elementos vacíos

Comprobamos si nuestro conjunto de datos contiene elementos vacíos:

```{r}
sapply(data, function(x) sum(is.na(x)))
```

Podemos observar que hay 86 elementos vacíos entre las variables Experience_Years, Salary...10E4 y Offer_History. Procederemos a emplear un método de imputación de valores basada en k vecinos más próximos. Utilizaremos la función kNN de la libreria VIM:

```{r}
suppressWarnings(suppressMessages(library(VIM)))

data$Experience_Years <- kNN(data)$Experience_Years
data$Salary...10E4 <- kNN(data)$Salary...10E4
data$Offer_History <- kNN(data)$Offer_History

sapply(data, function(x) sum(is.na(x)))
```

Después de la imputación de valores, podemos comprobar que ya no existen valores vacíos en nuestro conjunto de datos.

## 3.2. Valores extremos

Identificaremos los valores outliers de dos formas diferentes, utilizando un diagrama de caja y utilizando la función boxplots.stats() de R. Representaremos los datos de las variables numéricas Score y Salary...10E4. Primeramente representaremos la variable Score:

```{r}
boxplot(data$Score)
boxplot.stats(data$Score)$out
```

Podemos observar que la variable Score contiene muchos outliers. En este caso, podemos deshacernos de los valores más lejanos, ya que aunque haya valores fuera del rango, no podemos asumir que sean outliers y no personas altamente cualificadas para ser contratadas. Para deshacernos de los outliers, le daremos valor vacío a partir de cierto rango y después utilizaremos la función kNN nuevamente para la imputación de los valores:

```{r}
data$Score[data$Score > 23000] <- NA

data$Score <- kNN(data)$Score

boxplot(data$Score)
```

Puede observarse que han desaparecido los outliers más lejanos. Continuaremos con la variable Salary...10E4:

```{r}
boxplot(data$Salary...10E4)
boxplot.stats(data$Salary...10E4)$out
```

```{r}
data$Salary...10E4[data$Salary...10E4 > 500] <- NA

data$Salary...10E4 <- kNN(data)$Salary...10E4

boxplot(data$Salary...10E4)
```

En la variable Salary...10E4, hemos realizado el mismo proceso que en la variable anterior.

## 3.3. Exportación de los datos preprocesados

Después de leer y validar el conjunto de datos, limpieza de los elementos vacíos y extremos, procedemos a guardar los datos en un fichero denominado "recruitment_decision_tree_clean.csv":

```{r}
write.csv(data, "recruitment_decision_tree_clean.csv")
```


# 4. Análisis de los datos

## 4.1. Selección de datos

Pasamos a la selección de las variables de interés para su análisis estadístico posterior. Encontramos aquí las variables categóricas más relevantes.

```{r}
# Per gender
data.women <- data[data$Gender == "Female", ]
data.men <- data[data$Gender == "Male", ]

# Per location type
data.urban <- data[data$Location == "Urban", ]
data.semiurban <- data[data$Location == "Semiurban", ]
data.rural <- data[data$Location == "Rural", ]

# Per education level
data.graduated <- data[data$Education == "Graduate", ]
data.not_graduated <- data[data$Education == "Not Graduate", ]

# Target var: recruitment status
data.recruited <- data[data$Recruitment_Status == "Y", ]
data.not_recruited <- data[data$Recruitment_Status == "N", ]
```

## 4.2. Comprobación de normalidad y homogeneidad de la varianza

Se comprueba ahora la normalidad de las variables cuantitativas, mediante el test de normalidad de Anderson-Darling. Si el p-valor de es superior al nivel de significancia de $\alpha = 0,05$, entonces podemos concluir que la variable en cuestión es normal.

```{r}
library(nortest)

num_vars <- c("Experience_Years", "Score", "Salary...10E4")
alpha <- 0.05

for (col in num_vars){
  p_value = ad.test(data[, col])$p.value
  if (p_value > alpha){
    print(paste0(col, ": Normal (p = ", p_value, ")"))
  } else {
    print(paste0(col, ": Not normal (p = ", p_value, ")"))
  }
}
```

Por tanto vemos que las tres variables numéricas siguen una distribución no normal.

Para estudiar la homogeneidad de las varianzas aplicamos el test de Fligner-Killeen. Se pretende comprobar esta en la relación del género de los candidatos con el salario asociado a estos. Para este test, la hipótesis nula, $H_0$, sostiene la igualdad de varianzas para ambos grupos. Por su parte, $H_1$ supondría varianzas diferentes.

Si el p-valor es superior a un nivel de significancia del 0,05, se aceptará dicha hipótesis nula y por tanto la igualdad de varianzas. Aplicamos el test sobre los salarios, una de las variables de interés a estudiar.

```{r}
# Salary
fligner.test(Salary...10E4 ~ Gender, data=data)
```

Puesto que el p-valor es mayor a 0,05, se acepta la hipótesis nula y por tanto se asume la igualdad de varianzas para ambas muestras.


## 4.3. Pruebas estadísticas

Realizamos ahora varios análisis estadísticos que nos permitan responder las preguntas de interés planteadas sobre el conjunto de datos.

### 4.3.1. Correlación de la experiencia y puntuación de los candidatos con el salario

Comprobamos la correlación de la experiencia y puntuación de los candidatos con el salario, con el fin de comprobar en qué medida están asociadas estas métricas con una mayor retribución económica.

```{r}
# Experience vs salary
corr_exp_salary = cor(data$Experience_Years, data$Salary...10E4)
print(paste("Correlation of experience and salary:", round(corr_exp_salary, 3)))
# Score vs salary
corr_score_salary = cor(data$Score, data$Salary...10E4)
print(paste("Correlation of score and salary:", round(corr_score_salary, 3)))
```

Vemos que la correlación entre la experiencia y el salario es más bien débil para las muestras recogidas en el conjunto de datos, con un valor de `r round(corr_exp_salary, 3)`. No obstante, la puntuación tiene una correlación superior, aunque todavía moderada, de `r round(corr_score_salary, 3)`.

### 4.3.2. Contraste de hipótesis: salario de mujeres y hombres

Se pretende comprobar además si el salario de las mujeres y el de los hombres es diferente. Para ello, realizamos un contraste de hipótesis bilateral definiendo:

* $H_0: \mu_{mujeres} = \mu_{hombres}$

* $H_1: \mu_{mujeres} \ne \mu_{hombres}$

Donde la hipótesis nula, $H_0$, corresponde a la igualdad de salarios, y la hipótesis alternativa $H_1$, corresponde a la desigualdad de estos. Si bien la distribución no es normal, contamos con un buen tamaño muestral muy superior a 30, por lo que el teorema del límite central nos permite realizar test estadístico sobre la media asumiendo la normalidad de esta.

```{r}
t.test(data.women$Salary...10E4, data.men$Salary...10E4,
       alternative="two.sided", conf.level=0.95)
```

Al obtener un `p-valor` inferior a 0.05, el valor de significancia para un nivel de confianza del 95%, rechazamos la hipótesis nula. Por tanto, podemos afirmar que los salarios de mujeres y hombres son diferentes.

Para concretar más, podemos aplicar una hipótesis unilateral que verifique si efectivamente y como se puede sospechar, los sueldos de las mujeres son inferiores a los de los hombres. Para ello, definimos ahora las hipótesis:

* $H_0: \mu_{mujeres} = \mu_{hombres}$

* $H_1: \mu_{mujeres} < \mu_{hombres}$

En este caso la hipótesis alternativa, $H_1$, corresponde al supuesto en el que las mujeres tienen un salario medio inferior al de los hombres. Realizamos el test estadístico.

```{r}
t.test(data.women$Salary...10E4, data.men$Salary...10E4,
       alternative="less", conf.level=0.95)
```

En este caso vemos, de nuevo, como el `p-valor` es inferior al nivel de significancia adoptado, por lo que se rechaza la hipótesis nula y se concluye que, la media de los salarios de las mujeres es inferior al de los hombres con una confianza del 95%.

### 4.3.3. Regresión logística

Puesto que buena parte de las variables con las que contamos son de tipo categórico, podemos comprobar la relación entre estas y si finalmente el candidato fue contratado o no.

Podemos comprobar si existe relación entre algunas variables y la variable objetivo mediante el test $\chi^2$ de Pearson.

```{r}
# Get relation for all variables
data.colnames <- colnames(data[, -(10)])
alpha <- 0.05
print("Checking against Recruitment_Status:")
for (col in data.colnames){
  p_value <- chisq.test(table(data$Recruitment_Status, data[, col]),
                        simulate.p.value=TRUE)$p.value
  p_value <- round(p_value, 4)
  if (p_value > 0.05){
    print(paste0(col, ": not related (p = ", p_value, ")"))
  } else {
    print(paste0(col, ": related (p = ", p_value, ")"))
  }
}
```

Vemos que las variables que mantienen relación con la contratación son, según dicho test la educación, el historial de ofertas y la localización. Asimismo, vemos que la experiencia con Python es marginalmente relevante, por lo que la añadimos por la información que pueda aportar al modelo. Reajustamos las referencias de estas variables, con el estado más bajo (no graduado, sin ofertas previas, localización rural y sin experiencia en Python) como tal.

```{r}
# Relevel related variables
data$Education_R <- relevel(data$Education, ref="Not Graduate")
data$Offer_History_R <- relevel(as.factor(data$Offer_History), ref="0")
data$Location_R <- relevel(data$Location, ref="Rural")
data$Python_exp_R <- relevel(data$Python_exp, ref="No")

# Logistic regression
logistic_formula <- Recruitment_Status ~ Education_R + Offer_History_R + Location_R + Python_exp_R
logistic_model <- glm(formula=logistic_formula, data=data,
                      family=binomial(link = 'logit'))

summary(logistic_model)
```

Vemos qu

```{r}
length(data$Gender[data$Gender == ""])
length(data$Python_exp[data$Python_exp == ""])
length(data$Internship[data$Internship == ""])
```

```{r}
python()
```


# 5. Representación de resultados


# 6. Resolución y conclusiones


# 7. Código